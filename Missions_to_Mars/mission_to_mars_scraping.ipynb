{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Browser Funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Initialize Browser Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run init_browser function and open it\n",
    "# browser = init_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars InSight's Mole Has Partially Backed Out of Its Hole\n",
      "After making progress over the past several weeks digging into the surface of Mars, InSight's mole has backed about halfway out of its hole this past weekend.\n"
     ]
    }
   ],
   "source": [
    "# Run init_browser function and open it\n",
    "browser = init_browser()\n",
    "# Visit https://mars.nasa.gov/news/\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Scrape page into Soup\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "# Get Title and Paragrapht Text\n",
    "news_title = soup.find('div', class_=\"content_title\").text\n",
    "news_p = soup.find('div', class_=\"article_teaser_body\").text\n",
    "\n",
    "browser.quit()\n",
    "print(news_title + \"\\n\" +  news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA23378_hires.jpg\n"
     ]
    }
   ],
   "source": [
    "# Run init_browser function and open it\n",
    "browser = init_browser()\n",
    "# Visit https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\n",
    "url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(url)\n",
    "\n",
    "# Scrape page into Soup\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "time.sleep(1)\n",
    "\n",
    "# Click in one of the images\n",
    "browser.click_link_by_partial_text('Curiosity')\n",
    "time.sleep(5)\n",
    "\n",
    "# Click in the button for more information\n",
    "browser.click_link_by_partial_text('more info')\n",
    "time.sleep(1)\n",
    "\n",
    "# Get the new url after clicking \"more info\" and visiting it\n",
    "url = browser.url\n",
    "browser.visit(url)\n",
    "time.sleep(1)\n",
    "\n",
    "# Scrape clicked page into Soup\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "\n",
    "# Get the base url to be used with relative paths\n",
    "parsed = urlparse(url)\n",
    "base_url = parsed.scheme +\"://\"+ parsed.netloc\n",
    "\n",
    "# Get the high resolution image from the accesed page\n",
    "featured_image_url = base_url +  soup.find('img', class_=\"main_image\")[\"src\"]\n",
    "\n",
    "browser.quit()\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "InSight sol 330 (2019-10-31) low -101.8ºC (-151.3ºF) high -24.8ºC (-12.6ºF)\n",
      "winds from the SSE at 5.4 m/s (12.2 mph) gusting to 20.8 m/s (46.5 mph)\n",
      "pressure at 7.00 hPa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run init_browser function and open it\n",
    "browser = init_browser()\n",
    "# Visit https://twitter.com/marswxreport?lang=en\n",
    "url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Scrape page into Soup\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "\n",
    "# Get the image URL\n",
    "\n",
    "# Get all the text\n",
    "mars_weather_p_a = soup.find(\"div\", class_=\"js-tweet-text-container\").text\n",
    "\n",
    "# Get the text in the last part\n",
    "mars_weather_a = soup.find(\"div\", class_=\"js-tweet-text-container\").findChildren()[1].text\n",
    "\n",
    "# Eliminate the last part of the text\n",
    "mars_weather = mars_weather_p_a.replace(mars_weather_a,'')\n",
    "\n",
    "browser.quit()\n",
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <thead>\n",
      "    <tr style=\"text-align: right;\">\n",
      "      <th></th>\n",
      "      <th>Value</th>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Description</th>\n",
      "      <th></th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <th>Equatorial Diameter:</th>\n",
      "      <td>6,792 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Polar Diameter:</th>\n",
      "      <td>6,752 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Mass:</th>\n",
      "      <td>6.39 × 10^23 kg (0.11 Earths)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Moons:</th>\n",
      "      <td>2 (Phobos &amp; Deimos)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Orbit Distance:</th>\n",
      "      <td>227,943,824 km (1.38 AU)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Orbit Period:</th>\n",
      "      <td>687 days (1.9 years)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Surface Temperature:</th>\n",
      "      <td>-87 to -5 °C</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>First Record:</th>\n",
      "      <td>2nd millennium BC</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Recorded By:</th>\n",
      "      <td>Egyptian astronomers</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n",
      "                                              Value\n",
      "Description                                        \n",
      "Equatorial Diameter:                       6,792 km\n",
      "Polar Diameter:                            6,752 km\n",
      "Mass:                 6.39 × 10^23 kg (0.11 Earths)\n",
      "Moons:                          2 (Phobos & Deimos)\n",
      "Orbit Distance:            227,943,824 km (1.38 AU)\n",
      "Orbit Period:                  687 days (1.9 years)\n",
      "Surface Temperature:                   -87 to -5 °C\n",
      "First Record:                     2nd millennium BC\n",
      "Recorded By:                   Egyptian astronomers\n"
     ]
    }
   ],
   "source": [
    "# Run init_browser function and open it\n",
    "browser = init_browser()\n",
    "# Visit https://space-facts.com/mars/\n",
    "url = \"https://space-facts.com/mars/\"\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Scrape with Paandas\n",
    "tables_df = pd.read_html(url)\n",
    "\n",
    "# Get first table with the facts\n",
    "mars_facts_df = tables_df[1]\n",
    "\n",
    "# Rename column of the dataframe\n",
    "mars_facts_df = mars_facts_df.rename(columns={0: \"Description\", 1: \"Value\"})\n",
    "\n",
    "\n",
    "# Use the titles as index\n",
    "mars_facts_df.set_index(\"Description\", inplace=True)\n",
    "\n",
    "# Convert the dataframe to html\n",
    "mars_facts_html = mars_facts_df.to_html()\n",
    "\n",
    "browser.quit()\n",
    "print (mars_facts_html)\n",
    "print (mars_facts_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}, {'title': 'Schiaparelli Hemisphere Enhanced', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif'}, {'title': 'Syrtis Major Hemisphere Enhanced', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif'}, {'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif'}]\n"
     ]
    }
   ],
   "source": [
    "# Run init_browser function and open it\n",
    "browser = init_browser()\n",
    "\n",
    "# Visit https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\n",
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "\n",
    "# Get the base url to be used with relative paths\n",
    "parsed = urlparse(url)\n",
    "base_url = parsed.scheme +\"://\"+ parsed.netloc\n",
    "\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Scrape page into Soup\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "\n",
    "# Get the image URL\n",
    "\n",
    "results = soup.find(\"div\", class_=\"collapsible results\")\n",
    "\n",
    "# Initialize the Dictionary\n",
    "hemisphere_image_urls = []\n",
    "# Loop through returned results\n",
    "for result in results:\n",
    "    # Error handling\n",
    "    try:\n",
    "        # Identify and return title of the image\n",
    "        title = result.find(\"div\").h3.text\n",
    "        \n",
    "        # Identify and return link to the high resolution image\n",
    "        link_parent = base_url + result.a['href']\n",
    "\n",
    "        # Use the link to the page to get the high resolution Page\n",
    "        link_son = link_parent\n",
    "        browser.visit(link_son)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Scrape the socond page into Soup\n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "\n",
    "        # Get the image URL of the high resolution URL\n",
    "        # For getting the Original .tif\n",
    "        link_son = soup.find(\"a\", text=\"Original\")['href']\n",
    "        \n",
    "        # For getting the Sample .jpg\n",
    "        #link_son = soup.find(\"a\", text=\"Sample\")['href']\n",
    "\n",
    "        # Print results only if title, price, and link are available\n",
    "        if (title and link_parent):\n",
    "            #print('-------------')\n",
    "            #print(title)\n",
    "            #print(link_parent)\n",
    "            #print(link_son)\n",
    "\n",
    "            # Create Dictionary\n",
    "            url_dict = {}\n",
    "            url_dict[\"title\"] = title\n",
    "            url_dict[\"img_url\"] = link_son\n",
    "            hemisphere_image_urls.append(url_dict)\n",
    "\n",
    "    except AttributeError as e:\n",
    "            #print(e)\n",
    "            pass\n",
    "\n",
    "browser.quit()\n",
    "print (hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Result Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_title': \"Mars InSight's Mole Has Partially Backed Out of Its Hole\",\n",
       " 'news_p': \"After making progress over the past several weeks digging into the surface of Mars, InSight's mole has backed about halfway out of its hole this past weekend.\",\n",
       " 'featured_image_url': 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA23378_hires.jpg',\n",
       " 'mars_weather': '\\nInSight sol 330 (2019-10-31) low -101.8ºC (-151.3ºF) high -24.8ºC (-12.6ºF)\\nwinds from the SSE at 5.4 m/s (12.2 mph) gusting to 20.8 m/s (46.5 mph)\\npressure at 7.00 hPa\\n',\n",
       " 'mars_facts_html': '<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Value</th>\\n    </tr>\\n    <tr>\\n      <th>Description</th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Equatorial Diameter:</th>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>Polar Diameter:</th>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.39 × 10^23 kg (0.11 Earths)</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Distance:</th>\\n      <td>227,943,824 km (1.38 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Period:</th>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>Surface Temperature:</th>\\n      <td>-87 to -5 °C</td>\\n    </tr>\\n    <tr>\\n      <th>First Record:</th>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>Recorded By:</th>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>',\n",
       " 'hemisphere_image_urls': [{'title': 'Cerberus Hemisphere Enhanced',\n",
       "   'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'},\n",
       "  {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "   'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif'},\n",
       "  {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "   'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif'},\n",
       "  {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "   'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store data in a dictionary\n",
    "scraping_results = {\n",
    "        \"news_title\": news_title,\n",
    "        \"news_p\": news_p,\n",
    "        \"featured_image_url\": featured_image_url,\n",
    "        \"mars_weather\": mars_weather,\n",
    "        \"mars_facts_html\": mars_facts_html,\n",
    "        \"hemisphere_image_urls\": hemisphere_image_urls\n",
    "    }\n",
    "scraping_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
